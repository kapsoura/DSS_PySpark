{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install openjdk-11-jdk-headless -qq\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.0/spark-3.4.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.4.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.0-bin-hadoop3\""
      ],
      "metadata": {
        "id": "QzyiPNJr0vM6",
        "outputId": "bccb3711-a308-4239-fb3e-3c07ef7139f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "^C\n",
            "\n",
            "gzip: stdin: unexpected end of file\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Unexpected EOF in archive\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjgIqlRf0hzd"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "      .master(\"local[1]\") \\\n",
        "      .appName(\"test\") \\\n",
        "      .getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkfyUkpu0hze"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = [\n",
        "  ('James','','Smith','1991-04-01',3000),\n",
        "  ('Michael','Rose','','2000-05-19',4000),\n",
        "  ('Robert','','Williams','1978-09-05',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17',-1)\n",
        "]\n",
        "\n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"salary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHF7uiC80hze"
      },
      "outputs": [],
      "source": [
        "df = spark.createDataFrame(data=data, schema = columns)\n",
        "\n",
        "df.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vscode_pyspark",
      "language": "python",
      "name": "vscode_pyspark"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}